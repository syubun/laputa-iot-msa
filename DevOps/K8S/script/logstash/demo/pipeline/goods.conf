input {
    stdin {
    }
    jdbc {
        # mysql 数据库链接,shop为数据库名
        jdbc_connection_string => "jdbc:mysql://mysql:3306/test"
        # 用户名和密码
        jdbc_user => "root"
        jdbc_password => "root"
        # 驱动
        jdbc_driver_library => "/usr/share/logstash/pipeline/jar/mysql-connector-java-5.1.45-bin.jar"
        # 驱动类名
        jdbc_driver_class => "com.mysql.jdbc.Driver"
        jdbc_paging_enabled => "true"
        jdbc_page_size => "50000"
        # 执行的sql 文件路径+名称
        statement_filepath => "/usr/share/logstash/pipeline/sql/goods.sql"
        # 设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
        schedule => "* * * * *"
        # 索引类型
        type => "_doc"
        record_last_run => true
        #上一个sql_last_value值的存放文件路径, 必须要在文件中指定字段的初始值
        last_run_metadata_path => "/usr/share/logstash/pipeline/tmp/goods_last_time.txt"
    }
}

filter {
    json {
        source => "message"
        remove_field => ["message"]
    }
}

output {
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "goods"
        document_id => "%{id}"
        #type  => "_doc"
        #user => elastic
        #password => BqaFvDD69Yll8OCO0Oo
    }
    stdout {
        codec => json_lines
    }
}
